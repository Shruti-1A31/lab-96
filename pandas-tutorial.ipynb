{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pandas_logo.svg/2560px-Pandas_logo.svg.png)\n\n# pandas Tutorial\n","metadata":{}},{"cell_type":"markdown","source":"## Content:\n1. [Introduction to pandas](#introduction_to_pandas)\n2. [The Basics of pandas](#basics_of_pandas)\n3. [pandas Series](#pandas_series)\n    * [Creating Series](#creating_series)\n    * [Accessing Series](#accessing_series)\n4. [pandas Dataframes](#pandas_dataframe)\n    * [Creating Dataframes](#creating_dataframe)\n    * [Accessing Dataframes](#accessing_dataframe)\n    * [Modifying Dataframes](#modifying_dataframe)\n        * [Adding Row](#adding_row)\n        * [Modifying Row](#modifying_row)\n        * [Adding Column](#adding_column)\n        * [Deleting Columns](#deleting_column)\n        * [Deleting Rows](#deleting_row)\n    * [Sorting Dataframes](#sorting_dataframe)\n    * [Filtering Data](#filtering_data)\n5. [Reading and Writing CSV Files](#reading_writing_csv)\n    * [Reading CSV File](#reading_csv)\n    * [Writing CSV File](#writing_csv)\n6. [Cleaning Empty Cells](#cleaning_empty_cells)\n7. [Cleaning Data of Wrong Format](#cleaning_data_wrong_format)\n8. [Cleaning Wrong Data](#cleaning_wrong_data)\n9. [Removing Duplicates](#removing_duplicates)\n10. [Group By](#group_by)\n11. [Time Series](#time_series)\n12. [pandas Ploting](#pandas_ploting) \n13. [References](#references) ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"introduction_to_pandas\"></a> <br>\n# Introduction to Pandas\nPandas is anpen-source BSD-licensed library built on top of NumPy and Python that provides high-performance easy-to-use data structures and data analysis tools.\n\nPandas has been one of the most commonly used tools for Data Science and Machine learning requires, which is used for data cleaning and analysis. Here, Pandas is the best tool for handling this real-world messy data. \n\n### Features of Pandas\n* Provides tools for loading data from different file formats into in-memory data objects.\n* Represents the data in tabular form.\n* Label-based Slicing, Indexing, and Subsetting can be performed on large datasets.\n* Merges and joins two datasets easily.\n* Pivoting and reshaping data sets.\n* Easy handling of missing data (represented as NaN) in both floating point and non-floating point data.\n* Size mutability: DataFrame and higher-dimensional object columns can be added and deleted.\n* Provides multiple features of time-series.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-25T06:28:39.140112Z","iopub.execute_input":"2023-08-25T06:28:39.140552Z","iopub.status.idle":"2023-08-25T06:28:39.179762Z","shell.execute_reply.started":"2023-08-25T06:28:39.140514Z","shell.execute_reply":"2023-08-25T06:28:39.178533Z"}}},{"cell_type":"markdown","source":"<a id=\"basics_of_pandas\"></a> <br>\n# The Basics to Pandas\n\nPandas pacage can be imported as below:","metadata":{}},{"cell_type":"code","source":"import pandas as pd   # import Pandas\nimport numpy as np    # import NumPy","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.510354Z","iopub.execute_input":"2023-10-04T10:26:25.510828Z","iopub.status.idle":"2023-10-04T10:26:25.546363Z","shell.execute_reply.started":"2023-10-04T10:26:25.510794Z","shell.execute_reply":"2023-10-04T10:26:25.545605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***NumPy*** and ***Pandas*** go hand-in-hand, as much of pandas is built on NumPy. It is, therefore, very convenient to import NumPy and put it in a ***np*** namespace. Likewise, pandas is imported and referenced with a ***pd***.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"primary_pandas_objects\"></a> <br>\n### Primary pandas objects\n\nPandas framework provides two primary objects \n* ***Series***\n* ***DataFrame***\n\n\n<a id=\"pandas_series\"></a> <br>\n# pandas Series\nThe base data structure of pandas is the Series object, which is designed to operate\nsimilar to a NumPy array but also adds index capabilities.\n\nSeries is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively  referred to as the index. \n\n<a id=\"creating_series\"></a> <br>\n## Creating Series\nThe basic method to create a Series is to call:\n\n> ***s = pandas.Series(data=None, index=None, dtype=None, name=None, copy=None, fastpath=False)***\n\nHere, *data* can be many different things:\n* an ndarray\n* a Python dict\n* a scalar value (like 5)\n\n#### From ndarray","metadata":{}},{"cell_type":"code","source":"# creating series from Python array\ns = pd.Series([1, 2, 3, 4])\nprint(s)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.547951Z","iopub.execute_input":"2023-10-04T10:26:25.548396Z","iopub.status.idle":"2023-10-04T10:26:25.557647Z","shell.execute_reply.started":"2023-10-04T10:26:25.548370Z","shell.execute_reply":"2023-10-04T10:26:25.556960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If data is an ndarray, index must be the same length as data. If no index is passed, one will be created having values [0, ..., len(data) - 1].","metadata":{}},{"cell_type":"code","source":"# creating series from ndarray of random numbers\ns = pd.Series(np.random.randn(5))\nprint(s)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.559318Z","iopub.execute_input":"2023-10-04T10:26:25.559617Z","iopub.status.idle":"2023-10-04T10:26:25.572842Z","shell.execute_reply.started":"2023-10-04T10:26:25.559594Z","shell.execute_reply":"2023-10-04T10:26:25.571398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generating series from ndarray of random numbers with string indices\ns = pd.Series(np.random.randn(5), index=[\"a\", \"b\", \"c\", \"d\", \"e\"])\nprint(s)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.574601Z","iopub.execute_input":"2023-10-04T10:26:25.575030Z","iopub.status.idle":"2023-10-04T10:26:25.590942Z","shell.execute_reply.started":"2023-10-04T10:26:25.574979Z","shell.execute_reply":"2023-10-04T10:26:25.589737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### From Dictionary","metadata":{}},{"cell_type":"code","source":"# creating series from a dictionary\nd = {\"b\": 1, \"a\": 0, \"c\": 2}\ns = pd.Series(d)\nprint(s)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.594055Z","iopub.execute_input":"2023-10-04T10:26:25.594720Z","iopub.status.idle":"2023-10-04T10:26:25.601459Z","shell.execute_reply.started":"2023-10-04T10:26:25.594692Z","shell.execute_reply":"2023-10-04T10:26:25.600737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = {\"a\": 0.0, \"b\": 1.0, \"c\": 2.0}\ns = pd.Series(d, index=[\"b\", \"c\", \"d\", \"a\"])\nprint(s)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.602372Z","iopub.execute_input":"2023-10-04T10:26:25.602960Z","iopub.status.idle":"2023-10-04T10:26:25.627112Z","shell.execute_reply.started":"2023-10-04T10:26:25.602934Z","shell.execute_reply":"2023-10-04T10:26:25.625725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here for index *d* it will assign *NaN* as there is no value assigned to the key *d*.\n\n#### From Scalar Values","metadata":{}},{"cell_type":"code","source":"s = pd.Series(5.0, index=[\"a\", \"b\", \"c\", \"d\", \"e\"])\nprint(s)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.628552Z","iopub.execute_input":"2023-10-04T10:26:25.628878Z","iopub.status.idle":"2023-10-04T10:26:25.638182Z","shell.execute_reply.started":"2023-10-04T10:26:25.628852Z","shell.execute_reply":"2023-10-04T10:26:25.637286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"accessing_series\"></a> <br>\n## Accessing Series\nSeries acts very similarly to a ndarray, and is a valid argument to most NumPy functions. ","metadata":{}},{"cell_type":"code","source":"s = pd.Series(np.random.randn(7), index=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"])    # string Index\n#s = pd.Series(np.random.randn(10))             # Integer index\nprint(\"Series s:\\n\", s)\n\nprint(\"\\ns[0]: \", s[0]) \nprint(\"\\ns['a']: \", s['a']) ","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.639803Z","iopub.execute_input":"2023-10-04T10:26:25.640146Z","iopub.status.idle":"2023-10-04T10:26:25.657592Z","shell.execute_reply.started":"2023-10-04T10:26:25.640114Z","shell.execute_reply":"2023-10-04T10:26:25.656514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Aother way of accessing element in pandas:","metadata":{}},{"cell_type":"code","source":"print(s[1])\nprint(s.loc[\"b\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.658640Z","iopub.execute_input":"2023-10-04T10:26:25.659071Z","iopub.status.idle":"2023-10-04T10:26:25.667172Z","shell.execute_reply.started":"2023-10-04T10:26:25.659027Z","shell.execute_reply":"2023-10-04T10:26:25.665737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"However, operations such as slicing will also slice the index.","metadata":{}},{"cell_type":"code","source":"print(\"s[:3]: \", s[:3])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.670914Z","iopub.execute_input":"2023-10-04T10:26:25.671342Z","iopub.status.idle":"2023-10-04T10:26:25.679388Z","shell.execute_reply.started":"2023-10-04T10:26:25.671311Z","shell.execute_reply":"2023-10-04T10:26:25.678634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"s[[6, 4, 1]]: \\n\", s[[6, 4, 1]])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.680917Z","iopub.execute_input":"2023-10-04T10:26:25.681183Z","iopub.status.idle":"2023-10-04T10:26:25.690778Z","shell.execute_reply.started":"2023-10-04T10:26:25.681162Z","shell.execute_reply":"2023-10-04T10:26:25.690077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To get series as NumPy array.","metadata":{}},{"cell_type":"code","source":"v = s.values\nprint(\"v: \", v)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.691534Z","iopub.execute_input":"2023-10-04T10:26:25.691788Z","iopub.status.idle":"2023-10-04T10:26:25.704339Z","shell.execute_reply.started":"2023-10-04T10:26:25.691767Z","shell.execute_reply":"2023-10-04T10:26:25.703477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mathematical operations\n","metadata":{}},{"cell_type":"code","source":"s = pd.Series([10, 20, 30, 40, 50])\n\nprint(\"Sum: \", s.sum())                   # Sum of all elements\nprint(\"Mean: \", s.mean())                 # Mean of all elements\nprint(\"Max: \", s.max())                   # Maximum value in the series\nprint(\"Standar Deviation: \", s.std())     # Standard deviation of elements","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.706029Z","iopub.execute_input":"2023-10-04T10:26:25.706341Z","iopub.status.idle":"2023-10-04T10:26:25.719523Z","shell.execute_reply.started":"2023-10-04T10:26:25.706300Z","shell.execute_reply":"2023-10-04T10:26:25.718498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"pandas_dataframe\"></a> <br>\n# pandas Dataframe\npandas Dataframe is generally the most commonly used pandas object. Dataframe is a 2-dimensional structure & can be compared to a table of rows and columns with columns of potentially different types..\n\nEach row can be identified by an integer index (0..N) or a label explicitly set when creating a DataFrame object. Each column can be of distinct type and is identified by a label.\n\n<a id=\"creating_dataframe\"></a> <br>\n## Creating pandas Dataframe\nThe basic method to create a Dataframe is to call:\n> ***s = pd.DataFrame(data=None, index=None, columns=None, dtype=None, copy=None)***\n\nDataFrame accepts many different kinds of input:\n* Dict of 1D ndarrays, lists, dicts, or Series\n* 2-D numpy.ndarray\n* Structured or record ndarray\n* A Series\n* Another DataFrame\n\nAlong with the data, you can optionally pass index (row labels) and columns (column labels) arguments. If you pass an index and / or columns, you are guaranteeing the index and / or columns of the resulting DataFrame.\n### From Dictionary","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame({'numbers': [1, 2, 3], 'colors': ['red', 'white', 'blue']})\nprint(\"df:\\n\", df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.720898Z","iopub.execute_input":"2023-10-04T10:26:25.721840Z","iopub.status.idle":"2023-10-04T10:26:25.737066Z","shell.execute_reply.started":"2023-10-04T10:26:25.721793Z","shell.execute_reply":"2023-10-04T10:26:25.735890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### From dict of Series or dicts","metadata":{}},{"cell_type":"code","source":"d = {\"one\": pd.Series([1.0, 2.0, 3.0], index=[\"a\", \"b\", \"c\"]),\n    \"two\": pd.Series([1.0, 2.0, 3.0, 4.0], index=[\"a\", \"b\", \"c\", \"d\"])}\n\ndf = pd.DataFrame(d)\nprint(\"df:\\n\", df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.739220Z","iopub.execute_input":"2023-10-04T10:26:25.739627Z","iopub.status.idle":"2023-10-04T10:26:25.751090Z","shell.execute_reply.started":"2023-10-04T10:26:25.739592Z","shell.execute_reply":"2023-10-04T10:26:25.749976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When a particular set of columns is passed along with a dict of data, the passed columns override the keys in the dict.\n\n### From ndarrays/lists","metadata":{}},{"cell_type":"code","source":"d = {\"one\": [1.0, 2.0, 3.0, 4.0], \"two\": [4.0, 3.0, 2.0, 1.0]}\n\ndf = pd.DataFrame(d)\nprint(\"df:\\n\", df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.752293Z","iopub.execute_input":"2023-10-04T10:26:25.752599Z","iopub.status.idle":"2023-10-04T10:26:25.765643Z","shell.execute_reply.started":"2023-10-04T10:26:25.752574Z","shell.execute_reply":"2023-10-04T10:26:25.764638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The ndarrays must all be the same length. If an index is passed, it must clearly also be the same length as the arrays. \n* If no index is passed, the result will be range(n), where n is the array length.","metadata":{}},{"cell_type":"code","source":"d = {\"one\": [1.0, 2.0, 3.0, 4.0], \"two\": [4.0, 3.0, 2.0, 1.0]}\n\ndf = pd.DataFrame(d, index=[\"a\", \"b\", \"c\", \"d\"])\nprint(\"df:\\n\", df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.769095Z","iopub.execute_input":"2023-10-04T10:26:25.769529Z","iopub.status.idle":"2023-10-04T10:26:25.782237Z","shell.execute_reply.started":"2023-10-04T10:26:25.769492Z","shell.execute_reply":"2023-10-04T10:26:25.781371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(9)                 # Set the seed for a reproducible sample\n\ndf = pd.DataFrame(np.random.rand(5, 3), columns=list('ABC'))\nprint(\"df:\\n\", df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.783093Z","iopub.execute_input":"2023-10-04T10:26:25.783387Z","iopub.status.idle":"2023-10-04T10:26:25.798027Z","shell.execute_reply.started":"2023-10-04T10:26:25.783363Z","shell.execute_reply":"2023-10-04T10:26:25.796715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### From structured or record array","metadata":{}},{"cell_type":"code","source":"data = np.zeros((2,), dtype=[(\"A\", \"i4\"), (\"B\", \"f4\"), (\"C\", \"a10\")])\ndata[:] = [(1, 2.0, \"Hello\"), (2, 3.0, \"World\")]\ndf = pd.DataFrame(data)\nprint(\"df:\\n\", df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.799289Z","iopub.execute_input":"2023-10-04T10:26:25.799612Z","iopub.status.idle":"2023-10-04T10:26:25.817171Z","shell.execute_reply.started":"2023-10-04T10:26:25.799586Z","shell.execute_reply":"2023-10-04T10:26:25.815772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### From a list of dicts","metadata":{}},{"cell_type":"code","source":"data = [{\"a\": 1, \"b\": 2}, {\"a\": 5, \"b\": 10, \"c\": 20}]\ndf = pd.DataFrame(data)\nprint(\"df:\\n\", df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.818524Z","iopub.execute_input":"2023-10-04T10:26:25.818944Z","iopub.status.idle":"2023-10-04T10:26:25.830580Z","shell.execute_reply.started":"2023-10-04T10:26:25.818911Z","shell.execute_reply":"2023-10-04T10:26:25.829209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### From a Series\nThe result will be a DataFrame with the same index as the input Series, and with one column whose name is the original\nname of the Series (only if no other column name provided).","metadata":{}},{"cell_type":"code","source":"s = pd.Series([1.0, 2.0, 3.0], index=[\"a\", \"b\", \"c\"])\ndf = pd.DataFrame(s)\nprint(\"df:\\n\", df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.832224Z","iopub.execute_input":"2023-10-04T10:26:25.832649Z","iopub.status.idle":"2023-10-04T10:26:25.845525Z","shell.execute_reply.started":"2023-10-04T10:26:25.832613Z","shell.execute_reply":"2023-10-04T10:26:25.844048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = pd.Series([1.0, 2.0, 3.0], index=[\"a\", \"b\", \"c\"])\ndf = pd.DataFrame(s, columns=[\"c1\"])\nprint(\"df:\\n\", df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.847186Z","iopub.execute_input":"2023-10-04T10:26:25.847585Z","iopub.status.idle":"2023-10-04T10:26:25.859983Z","shell.execute_reply.started":"2023-10-04T10:26:25.847556Z","shell.execute_reply":"2023-10-04T10:26:25.858514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### From Another Dataframe","metadata":{}},{"cell_type":"code","source":"df1 = df                    # Assign dataframe into another dataframe\nprint(\"df1:\\n\", df1)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.861726Z","iopub.execute_input":"2023-10-04T10:26:25.862114Z","iopub.status.idle":"2023-10-04T10:26:25.875934Z","shell.execute_reply.started":"2023-10-04T10:26:25.862086Z","shell.execute_reply":"2023-10-04T10:26:25.874504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = df.copy()             # copy object into another dataframe\nprint(\"df2:\\n\", df2)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.877489Z","iopub.execute_input":"2023-10-04T10:26:25.877870Z","iopub.status.idle":"2023-10-04T10:26:25.888230Z","shell.execute_reply.started":"2023-10-04T10:26:25.877843Z","shell.execute_reply":"2023-10-04T10:26:25.887475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"accessing_dataframe\"></a> <br>\n## Accessing pandas Dataframe\nWe can access data of DataFrames in many ways,\n* Values\n* Columns\n* Rows\n\n### Accssing using Values\n####  By using row name and row index number\nUsing the row name and row index number along with the column, we can easily access a single value of a DataFrame.\n","metadata":{}},{"cell_type":"code","source":"d = {'EmpId' : ['E01','E02','E03','E04'],    \n       'EmpName' : ['Raj','Atul','Reena','Ayushi'],    \n       'Department' : ['IT','IT','HR','Accounts']}    \ndf = pd.DataFrame(d, index=['First','Second','Third','Fourth'])\nprint(\"df:\\n\", df)\n\nprint()\nprint(df.EmpName['Third'])   ##Access using row name    \nprint()\nprint(df.Department[2])        ## Access using row index","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.889129Z","iopub.execute_input":"2023-10-04T10:26:25.889396Z","iopub.status.idle":"2023-10-04T10:26:25.903723Z","shell.execute_reply.started":"2023-10-04T10:26:25.889374Z","shell.execute_reply":"2023-10-04T10:26:25.902619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### By using at and iat attributes\nWe can also access a single value of a DataFrame with the help of “at” and “iat” attributes.\n\n* *at*\n    * Access a single value for a row/column pair by label.\n\n* *iat*\n    * Access a single value for a row/column pair by integer position.","metadata":{}},{"cell_type":"code","source":"print(df.at['Second','EmpName'])\nprint()\nprint(df.iat[2,2])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.908579Z","iopub.execute_input":"2023-10-04T10:26:25.909689Z","iopub.status.idle":"2023-10-04T10:26:25.914882Z","shell.execute_reply.started":"2023-10-04T10:26:25.909660Z","shell.execute_reply":"2023-10-04T10:26:25.914137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Accessing Single Column","metadata":{}},{"cell_type":"code","source":"print(df['EmpName'])\nprint()\nprint(df.EmpName)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.915883Z","iopub.execute_input":"2023-10-04T10:26:25.916871Z","iopub.status.idle":"2023-10-04T10:26:25.930259Z","shell.execute_reply.started":"2023-10-04T10:26:25.916845Z","shell.execute_reply":"2023-10-04T10:26:25.929010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Accessing Multiple Columns","metadata":{}},{"cell_type":"code","source":"print(df[['EmpName','Department']] )","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.931244Z","iopub.execute_input":"2023-10-04T10:26:25.931582Z","iopub.status.idle":"2023-10-04T10:26:25.946063Z","shell.execute_reply.started":"2023-10-04T10:26:25.931556Z","shell.execute_reply":"2023-10-04T10:26:25.944694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accessing Rows\n\n#### By using loc and iloc\nWe can access a single row and multiple rows of a DataFrame with the help of “loc” and “iloc”\n\n* *loc*\n    * Access group of values using labels.\n* *iloc*\n    * Access group of rows and columns by integer position(s).","metadata":{}},{"cell_type":"code","source":"print(df.loc[['Second']])   # Access row using location, pass row name  \nprint()\nprint(df.iloc[[2]])         # Access row using row index number  ","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.947469Z","iopub.execute_input":"2023-10-04T10:26:25.947740Z","iopub.status.idle":"2023-10-04T10:26:25.963692Z","shell.execute_reply.started":"2023-10-04T10:26:25.947718Z","shell.execute_reply":"2023-10-04T10:26:25.962401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Different forms of “loc” and “iloc”","metadata":{}},{"cell_type":"code","source":"# Fetching all rows and columns from dataframe\ndf.loc[:]","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.965211Z","iopub.execute_input":"2023-10-04T10:26:25.965512Z","iopub.status.idle":"2023-10-04T10:26:25.981726Z","shell.execute_reply.started":"2023-10-04T10:26:25.965489Z","shell.execute_reply":"2023-10-04T10:26:25.980451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fetching all row starting from ‘First’ and fetching all columns.\nprint(df.loc['First' : , :])\nprint()\nprint(df.iloc[ 0 : , : ])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.982793Z","iopub.execute_input":"2023-10-04T10:26:25.983112Z","iopub.status.idle":"2023-10-04T10:26:25.994224Z","shell.execute_reply.started":"2023-10-04T10:26:25.983086Z","shell.execute_reply":"2023-10-04T10:26:25.992793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fetching rows starting from ‘First’ till the ‘Third’ with all columns.\nprint(df.loc [:'Third', :])\nprint()\nprint(df.iloc [:3, :])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:25.996015Z","iopub.execute_input":"2023-10-04T10:26:25.996405Z","iopub.status.idle":"2023-10-04T10:26:26.010498Z","shell.execute_reply.started":"2023-10-04T10:26:25.996377Z","shell.execute_reply":"2023-10-04T10:26:26.009521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fetching row starting from ‘Second’ and end to ‘Third’ with all columns.\nprint(df.loc['Second':'Third', :])\nprint()\nprint(df.iloc [1:3, :])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.011514Z","iopub.execute_input":"2023-10-04T10:26:26.011809Z","iopub.status.idle":"2023-10-04T10:26:26.023652Z","shell.execute_reply.started":"2023-10-04T10:26:26.011784Z","shell.execute_reply":"2023-10-04T10:26:26.022404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fetching all rows with ‘EmpName’ column to end column.\nprint(df.loc [:, 'EmpName': ])\nprint()\nprint(df.iloc [:, 1:])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.025204Z","iopub.execute_input":"2023-10-04T10:26:26.025514Z","iopub.status.idle":"2023-10-04T10:26:26.036292Z","shell.execute_reply.started":"2023-10-04T10:26:26.025489Z","shell.execute_reply":"2023-10-04T10:26:26.035105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fetching all rows till column EmpName.\nprint(df.loc [:, :'EmpName'])\nprint()\nprint(df.iloc [:, :2])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.037938Z","iopub.execute_input":"2023-10-04T10:26:26.038258Z","iopub.status.idle":"2023-10-04T10:26:26.057825Z","shell.execute_reply.started":"2023-10-04T10:26:26.038226Z","shell.execute_reply":"2023-10-04T10:26:26.056696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fetching rows starting with ‘Second’ till ‘Third’ and columns from ‘EmpName’ till ‘Department’\nprint(df.loc['Second':'Third', 'EmpName':'Department'])\nprint()\nprint(df.iloc[1:3, 1:3])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.059642Z","iopub.execute_input":"2023-10-04T10:26:26.060603Z","iopub.status.idle":"2023-10-04T10:26:26.076465Z","shell.execute_reply.started":"2023-10-04T10:26:26.060565Z","shell.execute_reply":"2023-10-04T10:26:26.074855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"modifying_dataframe\"></a> <br>\n## Modifying Dataframe\n\n\n<a id=\"adding_row\"></a> <br>\n### Adding a Row\n \n#### using loc\n* “loc” attribute is also used to add a new row in DataFrame.","metadata":{}},{"cell_type":"code","source":"df.loc['Fifth', : ] = ['E05', 'Nakul', 'HR']\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.078535Z","iopub.execute_input":"2023-10-04T10:26:26.078949Z","iopub.status.idle":"2023-10-04T10:26:26.089351Z","shell.execute_reply.started":"2023-10-04T10:26:26.078913Z","shell.execute_reply":"2023-10-04T10:26:26.088035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc['Sixth']=['E06', 'Rahul', 'Accounts']\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.091193Z","iopub.execute_input":"2023-10-04T10:26:26.091620Z","iopub.status.idle":"2023-10-04T10:26:26.108926Z","shell.execute_reply.started":"2023-10-04T10:26:26.091585Z","shell.execute_reply":"2023-10-04T10:26:26.107766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc['Seventh','EmpName':'Department'] = ['Vipul', 'IT'] \nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.110648Z","iopub.execute_input":"2023-10-04T10:26:26.110952Z","iopub.status.idle":"2023-10-04T10:26:26.119706Z","shell.execute_reply.started":"2023-10-04T10:26:26.110926Z","shell.execute_reply":"2023-10-04T10:26:26.118672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we don’t pass the column value then it automatically takes ‘NaN’. Like in the above example we don't pass EmpId for Seventh row, then it takes it as NaN.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"modifying_row\"></a> <br>\n### Modifying a Row","metadata":{}},{"cell_type":"code","source":"df.EmpId['Seventh'] = 'E07'\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.121031Z","iopub.execute_input":"2023-10-04T10:26:26.121379Z","iopub.status.idle":"2023-10-04T10:26:26.132981Z","shell.execute_reply.started":"2023-10-04T10:26:26.121353Z","shell.execute_reply":"2023-10-04T10:26:26.132321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"adding_column\"></a> <br>\n### Adding a column\n* It is very easy to add a column into an existing DataFrame. We can use the below syntax for adding a column into DataFrame.","metadata":{}},{"cell_type":"code","source":"#df['City'] = 'New Delhi'\ndf['City'] = ['New Delhi', np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.138124Z","iopub.execute_input":"2023-10-04T10:26:26.138517Z","iopub.status.idle":"2023-10-04T10:26:26.147790Z","shell.execute_reply.started":"2023-10-04T10:26:26.138488Z","shell.execute_reply":"2023-10-04T10:26:26.146350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"deleting_column\"></a> <br>\n### Deleting Columns\n* Del is used to delete a column from DataFrame.","metadata":{}},{"cell_type":"code","source":"del df['City']\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.149271Z","iopub.execute_input":"2023-10-04T10:26:26.149691Z","iopub.status.idle":"2023-10-04T10:26:26.164869Z","shell.execute_reply.started":"2023-10-04T10:26:26.149649Z","shell.execute_reply":"2023-10-04T10:26:26.163788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another way to delete column is using drop():\n> ***DataFrame.drop(labels=None, *, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')***\n* Drop specified labels from rows or columns.\n* Remove rows or columns by specifying label names and corresponding axis, or by specifying directly index or column names.\n\n***Note:*** drop function drops columns and rows but it does not update original dataframe. It returns updated dataframe as return value.","metadata":{}},{"cell_type":"code","source":"df['City'] = 'New Delhi'   # Add city column\nprint(df, \"\\n\")\n\ndf_new = df.drop(columns=['City'])\nprint(df_new)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.166038Z","iopub.execute_input":"2023-10-04T10:26:26.166479Z","iopub.status.idle":"2023-10-04T10:26:26.183902Z","shell.execute_reply.started":"2023-10-04T10:26:26.166436Z","shell.execute_reply":"2023-10-04T10:26:26.182364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"deleting_row\"></a> <br>\n### Deleting rows\n* drop() is used to delete rows from DataFrame.","metadata":{}},{"cell_type":"code","source":"df_new = df.drop(['Third', 'Fifth'])\nprint(df_new)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.185660Z","iopub.execute_input":"2023-10-04T10:26:26.186049Z","iopub.status.idle":"2023-10-04T10:26:26.195890Z","shell.execute_reply.started":"2023-10-04T10:26:26.186021Z","shell.execute_reply":"2023-10-04T10:26:26.194401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"sorting_dataframe\"></a> <br>\n\n## Sorting Dataframes\n* We can use *sort_values* function to sort pandas dataframe.\n\n> ***DataFrame.sort_values(by, *, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)***\n\n* *by*: \n    * str or list of str\n    * Name or list of names to sort by.\n    * if axis is 0 or ‘index’ then by may contain index levels and/or column labels.\n    * if axis is 1 or ‘columns’ then by may contain column levels and/or index labels.\n\n* *axis*: \n    * “{0 or ‘index’, 1 or ‘columns’}”, default 0\n    * Axis to be sorted.\n\n* *ascending*: \n    * bool or list of bool, default True\n    * Sort ascending vs. descending. Specify list for multiple sort orders. If this is a list of bools, must match the length of the by.","metadata":{}},{"cell_type":"code","source":"print(df)\nprint()\ndf_new=df.sort_values(by=['EmpName'], ascending=False) # can specify multiple columns in a list as well.\nprint(df_new)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.197846Z","iopub.execute_input":"2023-10-04T10:26:26.198172Z","iopub.status.idle":"2023-10-04T10:26:26.211192Z","shell.execute_reply.started":"2023-10-04T10:26:26.198145Z","shell.execute_reply":"2023-10-04T10:26:26.210099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df)\nprint()\ndf_new=df.sort_values(by=['Seventh'], axis=1, ascending=True) # can specify multiple columns in a list as well.\nprint(df_new)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.213006Z","iopub.execute_input":"2023-10-04T10:26:26.214150Z","iopub.status.idle":"2023-10-04T10:26:26.232214Z","shell.execute_reply.started":"2023-10-04T10:26:26.214105Z","shell.execute_reply":"2023-10-04T10:26:26.230700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"filtering_data\"></a> <br>\n# Filtering Data","metadata":{}},{"cell_type":"code","source":"df_new=df[df.Department==\"IT\"]\nprint(df_new)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.233996Z","iopub.execute_input":"2023-10-04T10:26:26.234448Z","iopub.status.idle":"2023-10-04T10:26:26.244135Z","shell.execute_reply.started":"2023-10-04T10:26:26.234392Z","shell.execute_reply":"2023-10-04T10:26:26.243298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"reading_writing_csv\"></a> <br>\n# Reading and Writing CSV Files\n\n\n<a id=\"reading_csv\"></a> <br>\n## Reading CSV File\nWe can use read_csv() to read a comma-separated values (csv) file into DataFrame.\n\n> ***pandas.read_csv(filepath_or_buffer, *, sep=_NoDefault.no_default, delimiter=None, ...)***\n* *filepath_or_bufferstr*:\n    * path object or file-like object\n    * Any valid string path is acceptable. \n* *sep*:\n    * str, default ‘,’\n    * Character or regex pattern to treat as the delimiter. \n* *delimiter*:\n    * Alias for sep.","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(r'../input/titanic/train.csv')\n\n# Get first five rows\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.245489Z","iopub.execute_input":"2023-10-04T10:26:26.245996Z","iopub.status.idle":"2023-10-04T10:26:26.283902Z","shell.execute_reply.started":"2023-10-04T10:26:26.245969Z","shell.execute_reply":"2023-10-04T10:26:26.283161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get first five rows\ndf.tail()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.285146Z","iopub.execute_input":"2023-10-04T10:26:26.285593Z","iopub.status.idle":"2023-10-04T10:26:26.300771Z","shell.execute_reply.started":"2023-10-04T10:26:26.285567Z","shell.execute_reply":"2023-10-04T10:26:26.299923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get shape of the dataframe\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.301962Z","iopub.execute_input":"2023-10-04T10:26:26.302437Z","iopub.status.idle":"2023-10-04T10:26:26.308384Z","shell.execute_reply.started":"2023-10-04T10:26:26.302393Z","shell.execute_reply":"2023-10-04T10:26:26.307254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get list of all the columns\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.310492Z","iopub.execute_input":"2023-10-04T10:26:26.311375Z","iopub.status.idle":"2023-10-04T10:26:26.325967Z","shell.execute_reply.started":"2023-10-04T10:26:26.311333Z","shell.execute_reply":"2023-10-04T10:26:26.324639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get rows index\ndf.index","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.327484Z","iopub.execute_input":"2023-10-04T10:26:26.328783Z","iopub.status.idle":"2023-10-04T10:26:26.338268Z","shell.execute_reply.started":"2023-10-04T10:26:26.328749Z","shell.execute_reply":"2023-10-04T10:26:26.336989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# General information about dataset\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.339806Z","iopub.execute_input":"2023-10-04T10:26:26.340192Z","iopub.status.idle":"2023-10-04T10:26:26.367666Z","shell.execute_reply.started":"2023-10-04T10:26:26.340156Z","shell.execute_reply":"2023-10-04T10:26:26.366260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# General description of dataset.\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.369367Z","iopub.execute_input":"2023-10-04T10:26:26.370535Z","iopub.status.idle":"2023-10-04T10:26:26.408977Z","shell.execute_reply.started":"2023-10-04T10:26:26.370500Z","shell.execute_reply":"2023-10-04T10:26:26.407516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We cab use read_excel() to read data from Excel file.","metadata":{}},{"cell_type":"code","source":"#df = pd.read_excel('data.xlsx')","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:26.410578Z","iopub.execute_input":"2023-10-04T10:26:26.410903Z","iopub.status.idle":"2023-10-04T10:26:26.415854Z","shell.execute_reply.started":"2023-10-04T10:26:26.410879Z","shell.execute_reply":"2023-10-04T10:26:26.414621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"writing_csv\"></a> <br>\n## Writing CSV File\nWe can use to_csv() to save dataframe into CSV file and to_excel() to save dataframe into Excel file.\n","metadata":{}},{"cell_type":"code","source":"# Save the DataFrame as a CSV file\ndf.to_csv('/kaggle/working/dataset.csv', index=False, sep=\"\\t\")\n\n# Save the DataFrame as an Excel file\ndf.to_excel('/kaggle/working/dataset.xlsx', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:27:05.341003Z","iopub.execute_input":"2023-10-04T10:27:05.341411Z","iopub.status.idle":"2023-10-04T10:27:05.438411Z","shell.execute_reply.started":"2023-10-04T10:27:05.341384Z","shell.execute_reply":"2023-10-04T10:27:05.437311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cleaning_empty_cells\"></a> <br>\n# Cleaning Empty Cells\n* pandas primarily uses the value np.nan to represent missing data. It is by default not included in computations.","metadata":{}},{"cell_type":"code","source":"# Read Titanic Datasset\ndf=pd.read_csv(r'../input/titanic/train.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.266456Z","iopub.execute_input":"2023-10-04T10:26:27.267096Z","iopub.status.idle":"2023-10-04T10:26:27.303529Z","shell.execute_reply.started":"2023-10-04T10:26:27.267068Z","shell.execute_reply":"2023-10-04T10:26:27.302061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can use dropna() to drop all the rows having NaN (not a number) data.","metadata":{}},{"cell_type":"code","source":"df_new = df.dropna()   # Drop rows with missing values\ndf_new","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.304928Z","iopub.execute_input":"2023-10-04T10:26:27.305468Z","iopub.status.idle":"2023-10-04T10:26:27.327998Z","shell.execute_reply.started":"2023-10-04T10:26:27.305405Z","shell.execute_reply":"2023-10-04T10:26:27.326607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new = df.dropna(axis=1)   # Drop cols with missing values\ndf_new","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.329651Z","iopub.execute_input":"2023-10-04T10:26:27.330105Z","iopub.status.idle":"2023-10-04T10:26:27.365507Z","shell.execute_reply.started":"2023-10-04T10:26:27.330073Z","shell.execute_reply":"2023-10-04T10:26:27.364018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can use fillna() to fill all the cells having NaN value with 0.","metadata":{}},{"cell_type":"code","source":"df_new = df.fillna(0)  # Fill missing values with 0\ndf_new","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.367186Z","iopub.execute_input":"2023-10-04T10:26:27.368730Z","iopub.status.idle":"2023-10-04T10:26:27.393577Z","shell.execute_reply.started":"2023-10-04T10:26:27.368687Z","shell.execute_reply":"2023-10-04T10:26:27.392506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can use any other value to fill in place of NaN.","metadata":{}},{"cell_type":"code","source":"df_new = df.fillna(value=7)  # Fill missing values with 0\ndf_new","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.394975Z","iopub.execute_input":"2023-10-04T10:26:27.395292Z","iopub.status.idle":"2023-10-04T10:26:27.431519Z","shell.execute_reply.started":"2023-10-04T10:26:27.395265Z","shell.execute_reply":"2023-10-04T10:26:27.429697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"isna() and isnull() is used to get the boolean mask where values are nan.\n* Returns True if value is NaN otherwise False.\n* isna() is used with pandas Dataframe object and isnull() is used with pandas series object.","metadata":{}},{"cell_type":"code","source":"\ndf.isna()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.434378Z","iopub.execute_input":"2023-10-04T10:26:27.434793Z","iopub.status.idle":"2023-10-04T10:26:27.471910Z","shell.execute_reply.started":"2023-10-04T10:26:27.434764Z","shell.execute_reply":"2023-10-04T10:26:27.470304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> DataFrame.any(*, axis=0, bool_only=False, skipna=True, **kwargs)\n* Return whether any element is True, potentially over an axis.\n* Returns False unless there is at least one element within a series or along a Dataframe axis that is True or equivalent (e.g. non-zero or non-empty).\n\nParameters\n* axis:\n    * {0 or ‘index’, 1 or ‘columns’, None}, default 0\n    * Indicate which axis or axes should be reduced. For Series this parameter is unused and defaults to 0.\n    * 0 / ‘index’ : reduce the index, return a Series whose index is the original column labels.\n    * 1 / ‘columns’ : reduce the columns, return a Series whose index is the original index.\n    * None : reduce all axes, return a scalar.\n\n* bool_only:\n    * bool, default False\n    * Include only boolean columns. Not implemented for Series.\n* skipna\n    * bool, default True\n    * Exclude NA/null values. If the entire row/column is NA and skipna is True, then the result will be False, as for an empty row/column. If skipna is False, then NA are treated as True, because these are not equal to zero.","metadata":{}},{"cell_type":"code","source":"# Get column which contains nan value\nvalue = df.isna().values.any(axis=0)\nprint(value)\n\nprint(df.columns[value])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.483285Z","iopub.execute_input":"2023-10-04T10:26:27.483852Z","iopub.status.idle":"2023-10-04T10:26:27.495100Z","shell.execute_reply.started":"2023-10-04T10:26:27.483813Z","shell.execute_reply":"2023-10-04T10:26:27.494137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get rows which contains nan value\nvalue = df.isna().values.any(axis=1)\n\nprint(df.index[value])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.496634Z","iopub.execute_input":"2023-10-04T10:26:27.497249Z","iopub.status.idle":"2023-10-04T10:26:27.512385Z","shell.execute_reply.started":"2023-10-04T10:26:27.497213Z","shell.execute_reply":"2023-10-04T10:26:27.511403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"cleaning_data_wrong_format\"></a> <br>\n# Cleaning Data of Wrong Format","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/wrong-data/wrong_data.csv')\n#print(df)\n\ndf['Date'] = pd.to_datetime(df['Date'])\n#print(df.to_string())\n\ndf.dropna(subset=['Date'], inplace=True)\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.514191Z","iopub.execute_input":"2023-10-04T10:26:27.515111Z","iopub.status.idle":"2023-10-04T10:26:27.543922Z","shell.execute_reply.started":"2023-10-04T10:26:27.515025Z","shell.execute_reply":"2023-10-04T10:26:27.542606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Note:*** The (inplace = True) will make sure that the method does NOT return a new DataFrame, but it will update the original DataFrame.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"cleaning_wrong_data\"></a> <br>\n# Cleaning Wrong Data\n* \"Wrong data\" does not have to be \"empty cells\" or \"wrong format\", it can just be wrong, like if someone registered \"199\" instead of \"1.99\".\n* Sometimes you can spot wrong data by looking at the data set, because you have an expectation of what it should be.\n\n\n* If you take a look at our data set, you can see that in row 7, the duration is 450, but for all the other rows the duration is between 30 and 60.\n* It doesn't have to be wrong, but taking in consideration that this is the data set of someone's workout sessions, we conclude with the fact that this person did not work out in 450 minutes.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/wrong-data/wrong_data.csv')\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.546035Z","iopub.execute_input":"2023-10-04T10:26:27.546453Z","iopub.status.idle":"2023-10-04T10:26:27.561018Z","shell.execute_reply.started":"2023-10-04T10:26:27.546397Z","shell.execute_reply":"2023-10-04T10:26:27.560020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How can we fix wrong values, like the one for \"Duration\" in row 7?\n* Replacing Values\n* Removing Rows\n\n### Replacing Values\n* One way to fix wrong values is to replace them with something else.\n* In our example, it is most likely a typo, and the value should be \"45\" instead of \"450\", and we could just insert \"45\" in row 7:","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/wrong-data/wrong_data.csv')\n#print(df)\n\ndf.loc[7, 'Duration'] = 45\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.562865Z","iopub.execute_input":"2023-10-04T10:26:27.563569Z","iopub.status.idle":"2023-10-04T10:26:27.579919Z","shell.execute_reply.started":"2023-10-04T10:26:27.563534Z","shell.execute_reply":"2023-10-04T10:26:27.578912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* To replace wrong data for larger data sets you can create some rules, e.g. set some boundaries for legal values, and replace any values that are outside of the boundaries.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/wrong-data/wrong_data.csv')\n#print(df)\n\nfor x in df.index:\n    if df.loc[x, \"Duration\"] > 120:\n        df.loc[x, \"Duration\"] = 120\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.581613Z","iopub.execute_input":"2023-10-04T10:26:27.582326Z","iopub.status.idle":"2023-10-04T10:26:27.600137Z","shell.execute_reply.started":"2023-10-04T10:26:27.582288Z","shell.execute_reply":"2023-10-04T10:26:27.599145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing Rows\n* Another way of handling wrong data is to remove the rows that contains wrong data.\n* This way you do not have to find out what to replace them with, and there is a good chance you do not need them to do your analyses.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/wrong-data/wrong_data.csv')\n#print(df)\n\nfor x in df.index:\n    if df.loc[x, \"Duration\"] > 120:\n        df.drop(x, inplace = True)\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.602048Z","iopub.execute_input":"2023-10-04T10:26:27.602567Z","iopub.status.idle":"2023-10-04T10:26:27.620027Z","shell.execute_reply.started":"2023-10-04T10:26:27.602525Z","shell.execute_reply":"2023-10-04T10:26:27.618361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"removing_duplicates\"></a> <br>\n# Removing Duplicates\n* Duplicate rows are rows that have been registered more than one time.\n* By taking a look at our test data set, we can assume that row 11 and 12 are duplicates.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/wrong-data/wrong_data.csv')\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.621822Z","iopub.execute_input":"2023-10-04T10:26:27.622284Z","iopub.status.idle":"2023-10-04T10:26:27.637456Z","shell.execute_reply.started":"2023-10-04T10:26:27.622247Z","shell.execute_reply":"2023-10-04T10:26:27.636511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The duplicated() method returns a Boolean values for each row:","metadata":{}},{"cell_type":"code","source":"print(df.duplicated())","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.639013Z","iopub.execute_input":"2023-10-04T10:26:27.639587Z","iopub.status.idle":"2023-10-04T10:26:27.649292Z","shell.execute_reply.started":"2023-10-04T10:26:27.639556Z","shell.execute_reply":"2023-10-04T10:26:27.648118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To remove duplicates, use the drop_duplicates() method.","metadata":{}},{"cell_type":"code","source":"df.drop_duplicates(inplace = True)\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.651108Z","iopub.execute_input":"2023-10-04T10:26:27.651775Z","iopub.status.idle":"2023-10-04T10:26:27.669056Z","shell.execute_reply.started":"2023-10-04T10:26:27.651736Z","shell.execute_reply":"2023-10-04T10:26:27.667672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"group_by\"></a> <br>\n# Group By","metadata":{}},{"cell_type":"code","source":"# Read Titanic Datasset\ndf=pd.read_csv(r'../input/titanic/train.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.671138Z","iopub.execute_input":"2023-10-04T10:26:27.671603Z","iopub.status.idle":"2023-10-04T10:26:27.699836Z","shell.execute_reply.started":"2023-10-04T10:26:27.671568Z","shell.execute_reply":"2023-10-04T10:26:27.698701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# group rows of the dataset based on Pclass\ngroups=df.groupby(['Pclass'])\n\ngroups.get_group(1) # Give some another no say 2 or 3 for its Pclass.","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.701583Z","iopub.execute_input":"2023-10-04T10:26:27.702280Z","iopub.status.idle":"2023-10-04T10:26:27.727925Z","shell.execute_reply.started":"2023-10-04T10:26:27.702242Z","shell.execute_reply":"2023-10-04T10:26:27.727110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Average Age per Pclass\ngroups['Age'].mean()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.729527Z","iopub.execute_input":"2023-10-04T10:26:27.730162Z","iopub.status.idle":"2023-10-04T10:26:27.742639Z","shell.execute_reply.started":"2023-10-04T10:26:27.730124Z","shell.execute_reply":"2023-10-04T10:26:27.740965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Min age per Pclass\ngroups['Age'].min()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.744558Z","iopub.execute_input":"2023-10-04T10:26:27.745764Z","iopub.status.idle":"2023-10-04T10:26:27.758579Z","shell.execute_reply.started":"2023-10-04T10:26:27.745725Z","shell.execute_reply":"2023-10-04T10:26:27.756905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Max age per Pclass\ngroups['Age'].max()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.760314Z","iopub.execute_input":"2023-10-04T10:26:27.761065Z","iopub.status.idle":"2023-10-04T10:26:27.777410Z","shell.execute_reply.started":"2023-10-04T10:26:27.761026Z","shell.execute_reply":"2023-10-04T10:26:27.776020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups['Age'].count()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.779196Z","iopub.execute_input":"2023-10-04T10:26:27.779927Z","iopub.status.idle":"2023-10-04T10:26:27.791875Z","shell.execute_reply.started":"2023-10-04T10:26:27.779883Z","shell.execute_reply":"2023-10-04T10:26:27.790741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"time_series\"></a> <br>\n# Time Series\n* pandas contains extensive capabilities and features for working with time series data for all domains. \n* Using the NumPy datetime64 and timedelta64 dtypes, pandas has consolidated a large number of features from other Python libraries like scikits.timeseries as well as created a tremendous amount of new functionality for manipulating time series data.","metadata":{}},{"cell_type":"code","source":"import datetime\n# Parsing time series information from various sources and formats\ndti = pd.to_datetime([\"1/1/2018\", np.datetime64(\"2018-01-01\"), datetime.datetime(2018, 1, 1)])\ndti","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.793705Z","iopub.execute_input":"2023-10-04T10:26:27.794522Z","iopub.status.idle":"2023-10-04T10:26:27.805257Z","shell.execute_reply.started":"2023-10-04T10:26:27.794350Z","shell.execute_reply":"2023-10-04T10:26:27.804055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate sequences of fixed-frequency dates and time spans\ndti = pd.date_range(\"2018-01-01\", periods=3, freq=\"H\")\ndti","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.807449Z","iopub.execute_input":"2023-10-04T10:26:27.808168Z","iopub.status.idle":"2023-10-04T10:26:27.823926Z","shell.execute_reply.started":"2023-10-04T10:26:27.808131Z","shell.execute_reply":"2023-10-04T10:26:27.822723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dti =pd.Series(pd.period_range(\"1/1/2011\", freq=\"M\", periods=5))\ndti","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.825387Z","iopub.execute_input":"2023-10-04T10:26:27.826958Z","iopub.status.idle":"2023-10-04T10:26:27.849065Z","shell.execute_reply.started":"2023-10-04T10:26:27.826913Z","shell.execute_reply":"2023-10-04T10:26:27.847385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Resampling or converting a time series to a particular frequency\nidx = pd.date_range(\"2018-01-01\", periods=10, freq=\"H\")\nts = pd.Series(range(len(idx)), index=idx)\nprint(\"Before Resampling:\\n\", ts)\nts = ts.resample(\"2H\").mean()\nprint(\"After Resampling:\\n\", ts)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.850372Z","iopub.execute_input":"2023-10-04T10:26:27.851107Z","iopub.status.idle":"2023-10-04T10:26:27.882905Z","shell.execute_reply.started":"2023-10-04T10:26:27.851064Z","shell.execute_reply":"2023-10-04T10:26:27.881970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"pandas_ploting\"></a> <br>\n# pandas Ploting\nPanda dataframe, timeseries data can be poltted using Matplotlib.","metadata":{}},{"cell_type":"code","source":"# We need pyplot from matplotlib, which is usually imported as plt\nimport matplotlib.pyplot as plt\n\n# Create an example DataFrame\ndata = {'Name': ['John', 'Alice', 'Bob'],\n        'Age': [25, 30, 35],\n        'Height': [175, 162, 180]}\ndf = pd.DataFrame(data)\n\n# Create a bar plot of age\ndf.plot(x='Name', y=['Age', 'Height'], kind='bar')\nplt.xlabel('Name')\nplt.title('Age Distribution')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:27.884763Z","iopub.execute_input":"2023-10-04T10:26:27.885748Z","iopub.status.idle":"2023-10-04T10:26:28.221677Z","shell.execute_reply.started":"2023-10-04T10:26:27.885704Z","shell.execute_reply":"2023-10-04T10:26:28.220213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts = pd.Series(np.random.randn(1000), index=pd.date_range(\"1/1/2000\",periods=1000))\nts = ts.cumsum()\nts.plot();","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:28.223221Z","iopub.execute_input":"2023-10-04T10:26:28.223620Z","iopub.status.idle":"2023-10-04T10:26:28.568223Z","shell.execute_reply.started":"2023-10-04T10:26:28.223590Z","shell.execute_reply":"2023-10-04T10:26:28.566707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(np.random.randn(1000, 4), \n                  index=pd.date_range(\"1/1/2000\",periods=1000), \n                  columns=[\"A\", \"B\", \"C\", \"D\"])\ndf = df.cumsum()\nplt.figure();\ndf.plot();\nplt.legend(loc='best');","metadata":{"execution":{"iopub.status.busy":"2023-10-04T10:26:28.570617Z","iopub.execute_input":"2023-10-04T10:26:28.571069Z","iopub.status.idle":"2023-10-04T10:26:29.066225Z","shell.execute_reply.started":"2023-10-04T10:26:28.571028Z","shell.execute_reply":"2023-10-04T10:26:29.065192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"references\"></a> <br>\n# References\n* https://pandas.pydata.org/pandas-docs/version/1.4.4/pandas.pdf\n* https://pandas.pydata.org/docs/user_guide/index.html\n* https://pandas.pydata.org/docs/reference/index.html\n* https://www.w3schools.com/python/pandas","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}